{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'python.data_processing'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataGenerator\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UnetModel\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#import tensorflow as tf\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\isabe\\Documents\\Hanze\\jaar_3_new\\kw2\\modelleren_van_kanker_brats\\notebooks\\python\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mThis package contains the source code for the project.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_processing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataProcessing\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_generator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataGenerator\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munet_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UnetModel\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'python.data_processing'"
     ]
    }
   ],
   "source": [
    "# https://youtu.be/ScdCQqLtnis\n",
    "\"\"\"\n",
    "@author: Sreenivas Bhattiprolu\n",
    "\n",
    "Code to train batches of cropped BraTS 2020 images using 3D U-net.\n",
    "\n",
    "Please get the data ready and define custom data gnerator using the other\n",
    "files in this directory.\n",
    "\n",
    "Images are expected to be 128x128x128x3 npy data (3 corresponds to the 3 channels for \n",
    "                                                  test_image_flair, test_image_t1ce, test_image_t2)\n",
    "Change the U-net input shape based on your input dataset shape (e.g. if you decide to only se 2 channels or all 4 channels)\n",
    "\n",
    "Masks are expected to be 128x128x128x3 npy data (4 corresponds to the 4 classes / labels)\n",
    "\n",
    "\n",
    "You can change input image sizes to customize for your computing resources.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from python import DataGenerator\n",
    "from python import UnetModel\n",
    "#import tensorflow as tf\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import segmentation_models_3D as sm\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "train_img_dir = \"../data/BraTS2020_TrainingData/input_data_128/train/images/\"\n",
    "train_mask_dir = \"../data/BraTS2020_TrainingData/input_data_128/train/masks/\"\n",
    "\n",
    "img_list = os.listdir(train_img_dir)\n",
    "msk_list = os.listdir(train_mask_dir)\n",
    "\n",
    "num_images = len(os.listdir(train_img_dir))\n",
    "\n",
    "img_num = random.randint(0,num_images-1)\n",
    "test_img = np.load(train_img_dir+img_list[img_num])\n",
    "test_mask = np.load(train_mask_dir+msk_list[img_num])\n",
    "test_mask = np.argmax(test_mask, axis=3)\n",
    "\n",
    "n_slice=random.randint(0, test_mask.shape[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.imshow(test_img[:,:,n_slice, 0], cmap='gray')\n",
    "plt.title('Image flair')\n",
    "plt.subplot(222)\n",
    "plt.imshow(test_img[:,:,n_slice, 1], cmap='gray')\n",
    "plt.title('Image t1ce')\n",
    "plt.subplot(223)\n",
    "plt.imshow(test_img[:,:,n_slice, 2], cmap='gray')\n",
    "plt.title('Image t2')\n",
    "plt.subplot(224)\n",
    "plt.imshow(test_mask[:,:,n_slice])\n",
    "plt.title('Mask')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "#Optional step of finding the distribution of each class and calculating appropriate weights\n",
    "#Alternatively you can just assign equal weights and see how well the model performs: 0.25, 0.25, 0.25, 0.25\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "columns = ['0', '1', '2', '3']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "train_mask_list = sorted(glob.glob('../data/BraTS2020_TrainingData/input_data_128/train/masks/*.npy'))\n",
    "\n",
    "for img in range(len(train_mask_list)):\n",
    "    print(img)\n",
    "    temp_image = np.load(train_mask_list[img])\n",
    "    temp_image = np.argmax(temp_image, axis=3)\n",
    "    val, counts = np.unique(temp_image, return_counts=True)\n",
    "    conts_dict = dict(zip(val.astype(str), counts))  # Ensure keys are strings matching 'columns'\n",
    "    \n",
    "    # Create a DataFrame from conts_dict with one row\n",
    "    temp_df = pd.DataFrame([conts_dict], columns=columns)\n",
    "    \n",
    "    # Concatenate the new row to the existing DataFrame\n",
    "    df = pd.concat([df, temp_df], ignore_index=True)\n",
    "\n",
    "# Calculate label sums\n",
    "label_0 = df['0'].sum()\n",
    "label_1 = df['1'].sum()\n",
    "label_2 = df['2'].sum()\n",
    "label_3 = df['3'].sum()\n",
    "total_labels = label_0 + label_1 + label_2 + label_3\n",
    "n_classes = 4\n",
    "\n",
    "# Class weights calculation: n_samples / (n_classes * n_samples_for_class)\n",
    "wt0 = round((total_labels / (n_classes * label_0)), 2) if label_0 != 0 else 0\n",
    "wt1 = round((total_labels / (n_classes * label_1)), 2) if label_1 != 0 else 0\n",
    "wt2 = round((total_labels / (n_classes * label_2)), 2) if label_2 != 0 else 0\n",
    "wt3 = round((total_labels / (n_classes * label_3)), 2) if label_3 != 0 else 0\n",
    "\n",
    "# Weights can be used for Dice loss\n",
    "\n",
    "#Weights are: 0.26, 22.53, 22.53, 26.21\n",
    "#wt0, wt1, wt2, wt3 = 0.26, 22.53, 22.53, 26.21\n",
    "#These weihts can be used for Dice loss \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Weights are: {wt0}, {wt1}, {wt2}, {wt3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "#Define the image generators for training and validation\n",
    "\n",
    "train_img_dir = \"../data/BraTS2020_TrainingData/input_data_128/train/images/\"\n",
    "train_mask_dir = \"../data/BraTS2020_TrainingData/input_data_128/train/masks/\"\n",
    "\n",
    "val_img_dir = \"../data/BraTS2020_TrainingData/input_data_128/val/images/\"\n",
    "val_mask_dir = \"../data/BraTS2020_TrainingData/input_data_128/val/masks/\"\n",
    "\n",
    "train_img_list=os.listdir(train_img_dir)\n",
    "train_mask_list = os.listdir(train_mask_dir)\n",
    "\n",
    "val_img_list=os.listdir(val_img_dir)\n",
    "val_mask_list = os.listdir(val_mask_dir)\n",
    "##################################\n",
    "\n",
    "########################################################################\n",
    "batch_size = 2\n",
    "\n",
    "train_img_datagen = DataGenerator.imageLoader(train_img_dir, train_img_list, \n",
    "                                train_mask_dir, train_mask_list, batch_size)\n",
    "\n",
    "val_img_datagen = DataGenerator.imageLoader(val_img_dir, val_img_list, \n",
    "                                val_mask_dir, val_mask_list, batch_size)\n",
    "\n",
    "#Verify generator.... In python 3 next() is renamed as __next__()\n",
    "img, msk = train_img_datagen.__next__()\n",
    "\n",
    "img_num = random.randint(0,img.shape[0]-1)\n",
    "test_img=img[img_num]\n",
    "test_mask=msk[img_num]\n",
    "test_mask=np.argmax(test_mask, axis=3)\n",
    "\n",
    "n_slice=random.randint(0, test_mask.shape[2])\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.imshow(test_img[:,:,n_slice, 0], cmap='gray')\n",
    "plt.title('Image flair')\n",
    "plt.subplot(222)\n",
    "plt.imshow(test_img[:,:,n_slice, 1], cmap='gray')\n",
    "plt.title('Image t1ce')\n",
    "plt.subplot(223)\n",
    "plt.imshow(test_img[:,:,n_slice, 2], cmap='gray')\n",
    "plt.title('Image t2')\n",
    "plt.subplot(224)\n",
    "plt.imshow(test_mask[:,:,n_slice])\n",
    "plt.title('Mask')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if GPU is available\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "tf.debugging.set_log_device_placement(True)  # Logs device placement\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###########################################################################\n",
    "#Define loss, metrics and optimizer to be used for training\n",
    "wt0, wt1, wt2, wt3 = 0.25,0.25,0.25,0.25\n",
    "\n",
    "dice_loss = sm.losses.DiceLoss(class_weights=np.array([wt0, wt1, wt2, wt3])) \n",
    "focal_loss = sm.losses.CategoricalFocalLoss()\n",
    "total_loss = dice_loss + (1 * focal_loss)\n",
    "\n",
    "metrics = ['accuracy', sm.metrics.IOUScore(threshold=0.5)]\n",
    "\n",
    "LR = 0.0001\n",
    "optim = keras.optimizers.Adam(LR)\n",
    "#######################################################################\n",
    "#Fit the model \n",
    "\n",
    "steps_per_epoch = len(train_img_list)//batch_size\n",
    "val_steps_per_epoch = len(val_img_list)//batch_size\n",
    "\n",
    "\n",
    "#from  unet_model import simple_unet_model\n",
    "\n",
    "model = UnetModel.simple_unet_model(IMG_HEIGHT=128, \n",
    "                          IMG_WIDTH=128, \n",
    "                          IMG_DEPTH=128, \n",
    "                          IMG_CHANNELS=3, \n",
    "                          num_classes=4)\n",
    "\n",
    "model.compile(optimizer = optim, loss=total_loss, metrics=metrics)\n",
    "print(model.summary())\n",
    "\n",
    "print(model.input_shape)\n",
    "print(model.output_shape)\n",
    "\n",
    "history=model.fit(train_img_datagen,\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          epochs=3,\n",
    "          verbose=1,\n",
    "          validation_data=val_img_datagen,\n",
    "          validation_steps=val_steps_per_epoch,\n",
    "          )\n",
    "\n",
    "model.save('brats_3d_test.hdf5')\n",
    "##################################################################\n",
    "\n",
    "\n",
    "#plot the training and validation IoU and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'y', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "from keras.models import load_model\n",
    "\n",
    "#Load model for prediction or continue training\n",
    "\n",
    "#For continuing training....\n",
    "#The following gives an error: Unknown loss function: dice_loss_plus_1focal_loss\n",
    "#This is because the model does not save loss function and metrics. So to compile and \n",
    "#continue training we need to provide these as custom_objects.\n",
    "#my_model = load_model('../notebooks/brats_3d_test.hdf5')\n",
    "\n",
    "#So let us add the loss as custom object... but the following throws another error...\n",
    "#Unknown metric function: iou_score\n",
    "my_model = load_model('../notebooks/brats_3d_test.hdf5', \n",
    "                      custom_objects={'dice_loss_plus_1focal_loss': total_loss})\n",
    "\n",
    "#Now, let us add the iou_score function we used during our initial training\n",
    "my_model = load_model('../notebooks/brats_3d_test.hdf5', \n",
    "                      custom_objects={'dice_loss_plus_1focal_loss': total_loss,\n",
    "                                      'iou_score':sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "#Now all set to continue the training process. \n",
    "history2=my_model.fit(train_img_datagen,\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          epochs=1,\n",
    "          verbose=1,\n",
    "          validation_data=val_img_datagen,\n",
    "          validation_steps=val_steps_per_epoch,\n",
    "          )\n",
    "#################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#For predictions you do not need to compile the model, so ...\n",
    "my_model = load_model('saved_models/brats_3d_100epochs_simple_unet_weighted_dice.hdf5', \n",
    "                      compile=False)\n",
    "\n",
    "\n",
    "#Verify IoU on a batch of images from the test dataset\n",
    "#Using built in keras function for IoU\n",
    "#Only works on TF > 2.0\n",
    "from keras.metrics import MeanIoU\n",
    "\n",
    "batch_size=8 #Check IoU for a batch of images\n",
    "test_img_datagen = imageLoader(val_img_dir, val_img_list, \n",
    "                                val_mask_dir, val_mask_list, batch_size)\n",
    "\n",
    "#Verify generator.... In python 3 next() is renamed as __next__()\n",
    "test_image_batch, test_mask_batch = test_img_datagen.__next__()\n",
    "\n",
    "test_mask_batch_argmax = np.argmax(test_mask_batch, axis=4)\n",
    "test_pred_batch = my_model.predict(test_image_batch)\n",
    "test_pred_batch_argmax = np.argmax(test_pred_batch, axis=4)\n",
    "\n",
    "n_classes = 4\n",
    "IOU_keras = MeanIoU(num_classes=n_classes)  \n",
    "IOU_keras.update_state(test_pred_batch_argmax, test_mask_batch_argmax)\n",
    "print(\"Mean IoU =\", IOU_keras.result().numpy())\n",
    "\n",
    "#############################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict on a few test images, one at a time\n",
    "#Try images: \n",
    "img_num = 82\n",
    "\n",
    "test_img = np.load(\"../data/BraTS2020_TrainingData/input_data_128/val/images/image_\"+str(img_num)+\".npy\")\n",
    "\n",
    "test_mask = np.load(\"../data/BraTS2020_TrainingData/input_data_128/val/masks/mask_\"+str(img_num)+\".npy\")\n",
    "test_mask_argmax=np.argmax(test_mask, axis=3)\n",
    "\n",
    "test_img_input = np.expand_dims(test_img, axis=0)\n",
    "test_prediction = my_model.predict(test_img_input)\n",
    "test_prediction_argmax=np.argmax(test_prediction, axis=4)[0,:,:,:]\n",
    "\n",
    "\n",
    "# print(test_prediction_argmax.shape)\n",
    "# print(test_mask_argmax.shape)\n",
    "# print(np.unique(test_prediction_argmax))\n",
    "\n",
    "\n",
    "#Plot individual slices from test predictions for verification\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "\n",
    "#n_slice=random.randint(0, test_prediction_argmax.shape[2])\n",
    "n_slice = 55\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(231)\n",
    "plt.title('Testing Image')\n",
    "plt.imshow(test_img[:,:,n_slice,1], cmap='gray')\n",
    "plt.subplot(232)\n",
    "plt.title('Testing Label')\n",
    "plt.imshow(test_mask_argmax[:,:,n_slice])\n",
    "plt.subplot(233)\n",
    "plt.title('Prediction on test image')\n",
    "plt.imshow(test_prediction_argmax[:,:, n_slice])\n",
    "plt.show()\n",
    "\n",
    "############################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelleren_van_kanker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
